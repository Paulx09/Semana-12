# -*- coding: utf-8 -*-
"""Te damos la bienvenida a Colaboratory

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

from pyspark.context import SparkContext

sc = SparkContext('local', 'test')

rdd = sc.parallelize(["b", "a", "c"])

rdd.map(lambda x:(x,1)).collect()

var_context = rdd.map(lambda x:(x,1))

var_context.collect()

rdd2 = sc.parallelize([6, 7, 8, 9])

rdd3  = sc.parallelize([1, 2, 3, 4])

rdd2.union(rdd3).collect()

"""Ejemplos a realizar"""

# Ejercicio 1: map()
from pyspark import SparkContext

sc = SparkContext.getOrCreate()

# Crear un RDD a partir de una lista
numbers = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

# Usar map para elevar al cuadrado
squared = numbers.map(lambda x: x ** 2)

squared.collect()

# Ejercicio 2: filter()
# Filtrar n√∫meros pares
even_numbers = numbers.filter(lambda x: x % 2 == 0)
even_numbers.collect()

# Ejercicio 3: flatMap()
phrases = sc.parallelize(["Hola mundo", "Apache Spark es genial"])

# Separar frases en palabras
words = phrases.flatMap(lambda x: x.split(" "))
words.collect()

# Ejercicio 4: union()
rdd_1 = sc.parallelize([1, 2, 3])
rdd_2 = sc.parallelize([4, 5, 6])

# Unir RDDs
combined = rdd_1.union(rdd_2)
combined.collect()

# Ejercicio 5: intersection()
rdd_3 = sc.parallelize([3, 4, 5])
intersection = rdd_1.intersection(rdd_3)
intersection.collect()

# Ejercicio 6: distinct()
duplicates = sc.parallelize([1, 1, 2, 3, 3, 4])
unique = duplicates.distinct()
unique.collect()

# Ejercicio 7: groupByKey()
pairs = sc.parallelize([('a', 1), ('b', 1), ('a', 2), ('b', 3)])
grouped = pairs.groupByKey()
for key, value in grouped.collect():
    print(key, list(value))

# Ejercicio 8: sortByKey()
pairs = sc.parallelize([('a', 1), ('b', 1), ('a', 2), ('b', 3)])

sorted_pairs = pairs.sortByKey()
sorted_pairs.collect()

# Ejercicio 9: join()
rddA = sc.parallelize([('a', 1), ('b', 2)])
rddB = sc.parallelize([('a', 3), ('b', 4), ('c', 5)])

joined = rddA.join(rddB)

joined.collect()

# Ejercicio 10: cogroup()
cogrouped = rddA.cogroup(rddB)
for key, value in cogrouped.collect():
    print(key, (list(value[0]), list(value[1])))

# Ejercicio 11: coalesce()
coalesced = duplicates.coalesce(1)
coalesced.collect()

# Ejercicio 12: reduce()
total = numbers.reduce(lambda x, y: x + y)
total

# Ejercicio 13: collect()
all_numbers = numbers.collect()
all_numbers

# Ejercicio 14: count()
count = numbers.count()
count

# Ejercicio 15: first()
first_number = numbers.first()
first_number

# Ejercicio 16: take()
first_three = numbers.take(3)
first_three

# Ejercicio 17: saveAsTextFile()
# Crear un RDD a partir de una lista
numbers = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

# Guardar el RDD en un archivo de texto
numbers.saveAsTextFile("file:///C:/Users/DOCENTE/Desktop/numbers.txt")

# Ejercicio 18: max() y min()
max_value = numbers.max()
min_value = numbers.min()
print(f"Max: {max_value}, Min: {min_value}")

# Ejercicio 19: countByKey()
counts = pairs.countByKey()
counts

# Ejercicio 20: foreach()
def print_element(x):
    print(x)

duplicates.foreach(print_element)

