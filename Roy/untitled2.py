# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GdQMVJBVuLN1O3dqYUCLxQeFAqExYbfa
"""

from pyspark import SparkContext

sc = SparkContext("local", "Ejemplo Count")

from pyspark.sql import SparkSession

# Inicializa SparkSession
spark = SparkSession.builder.appName("Leer CSV").getOrCreate()

# Lee el archivo CSV
df = spark.read.csv("data.csv", header=True, inferSchema=True)

# Muestra el contenido del DataFrame en formato tabular
df.show()

# Detiene el SparkSession

# Contar el número total de filas
total_filas = df.count()
print(f"Número total de filas: {total_filas}")

# Contar el número de registros por apellido
df_agrupado = df.groupBy("Apellido").count()
df_agrupado.show()

from pyspark.sql import SparkSession
from pyspark.sql import Row

nuevos_datos = [

    Row(Nombre='Ana', Apellido='Martínez', Correo_Electronico='ana.martinez@example.com', Telefono='111222333'),

    Row(Nombre='Luis', Apellido='Fernández', Correo_Electronico='luis.fernandez@example.com', Telefono='444555666')

]
df_nuevos = spark.createDataFrame(nuevos_datos)

# Agregar los nuevos datos al DataFrame existente
df_completo = df.union(df_nuevos)

# Mostrar el DataFrame completo
df_completo.show()

filas = df.take(3)


# Mostrar las filas

for fila in filas:

    print(fila)