# -*- coding: utf-8 -*-
"""Semana_12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12DVVEKStpTv99qZ2xFvyTgCEqEap5tAD

# **Caso de uso:** An치lisis de Ventas
"""

from pyspark.context import SparkContext

sc = SparkContext('local', 'test')

# Leer el archivo CSV
sales = sc.textFile("ventas.csv")

sales.collect()

from google.colab import drive
drive.mount('/content/drive')

# Ignorar la cabecera y dividir por comas
header = sales.first()  # Capturar la cabecera
data = sales.filter(lambda line: line != header).map(lambda line: line.split(";"))

# Filtramos los productos que se vendieron en m치s de 10 unidades
filt_sales = data.filter(lambda x: len(x) == 3 and int(x[1]) > 10)

# Calculamos el ingreso total por producto
# Ingreso total = Cantidad * Precio
ingresos_producto = filt_sales.map(lambda x: (x[0], int(x[1]) * float(x[2])))

# Calculamos el ingreso total por producto
total_ingresos = ingresos_producto.reduceByKey(lambda x, y: x + y)

# Aseguramos de que haya datos antes de llamar a .reduce
if total_ingresos.isEmpty():
    print("No hay ingresos para calcular.")
else:
    # Obtener el producto con el ingreso total m치s alto
    highest_revenue_product = total_ingresos.reduce(lambda x, y: x if x[1] > y[1] else y)
    print(f"Producto con el ingreso total m치s alto: {highest_revenue_product[0]} con ingresos de {highest_revenue_product[1]}")